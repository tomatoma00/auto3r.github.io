<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Auto3R automates 3D scanning and reconstruction via data-driven uncertainty quantification.">
  <meta name="keywords" content="Auto3R, 3D scanning, uncertainty quantification, reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification</title>

  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- Fonts and Icons -->
  <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&family=Noto+Sans:wght@400;500&family=Castoro:ital@0;1&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  
  <!-- Custom Styles -->
  <style>
    :root {
      --primary-color: #2563eb;
      --secondary-color: #4f46e5;
      --accent-color: #0ea5e9;
      --text-dark: #1e293b;
      --text-light: #64748b;
      --bg-light: #f8fafc;
      --border-color: #e2e8f0;
    }

    body {
      font-family: 'Noto Sans', sans-serif;
      color: var(--text-dark);
      background-color: var(--bg-light);
      line-height: 1.6;
    }

    .publication-title {
      font-family: 'Google Sans', sans-serif;
      font-weight: 700;
      color: var(--text-dark);
      line-height: 1.3;
      margin-bottom: 1.5rem !important;
    }

    .author-section {
      margin: 2rem 0;
    }

    .authors {
      font-size: 1.1rem;
      color: #1e3a8a;
      list-style: none;
      padding: 0;
      margin: 0 0 1rem 0;
      line-height: 1.5;
    }

    .authors li {
      margin-bottom: 0.5rem;
    }

    .affiliations {
      font-size: 1rem;
      color: #3b82f6;
      list-style: none;
      padding: 0;
      margin: 0;
      font-style: italic;
    }

    .abstract-section {
      background-color: white;
      padding: 1.5rem;
      border-radius: 0.5rem;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
      margin: 2rem 0;
      text-align: justify;
    }

    .abstract-title {
      font-family: 'Google Sans', sans-serif;
      font-weight: 500;
      font-size: 1.2rem;
      margin-bottom: 0.8rem;
      color: var(--primary-color);
    }

    .button-container {
      margin: 2rem 0;
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      justify-content: center;
    }

    .button {
      border-radius: 0.4rem !important;
      font-weight: 500 !important;
      transition: all 0.2s ease;
    }

    .button.is-primary {
      background-color: var(--primary-color) !important;
    }

    .button.is-primary:hover {
      background-color: #1d4ed8 !important;
      transform: translateY(-2px);
    }

    .button.is-info {
      background-color: var(--accent-color) !important;
    }

    .button.is-info:hover {
      background-color: #0284c7 !important;
      transform: translateY(-2px);
    }

    .media-container {
      margin: 2.5rem 0;
      background-color: white;
      padding: 1rem;
      border-radius: 0.5rem;
      box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    .media-title {
      font-family: 'Google Sans', sans-serif;
      font-weight: 500;
      margin-bottom: 1rem;
      color: var(--text-dark);
    }

    video, img {
      border-radius: 0.3rem;
      box-shadow: 0 2px 8px rgba(0,0,0,0.15);
    }

    .section {
      padding: 3rem 1.5rem !important;
    }

    .container {
      max-width: 900px !important;
    }

    /* Responsive adjustments */
    @media (max-width: 768px) {
      .publication-title {
        font-size: 1.8rem !important;
      }
      
      .authors {
        font-size: 1rem;
      }
      
      .affiliations {
        font-size: 0.9rem;
      }
      
      .button {
        width: 100%;
        margin: 0.5rem 0 !important;
      }
      
      .button-container {
        flex-direction: column;
      }
    }

    @media (min-width: 769px) {
      .abstract-section {
        padding: 2rem;
      }
    }
  </style>

  <link rel="icon" href="./static/images/favicon.svg">
</head>
<body>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- Title -->
          <h1 class="title is-1 publication-title">Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification</h1>
          
          <!-- Authors and Affiliations -->
          <div class="author-section">
            <ul class="authors">
              <li>Chentao Shen, Sizhe Zheng, Bingqian Wu, Yaohua Feng</li>
              <li>Yuanchen Fei, Mingyu Mei, Hanwen Jiang, Xiangru Huang</li>
            </ul>
            <ul class="affiliations">
              <li>Zhejiang University, Westlake University, Hunan University, Adobe Research</li>
            </ul>
          </div>
          
          <!-- Abstract -->
          <div class="abstract-section">
            <div class="abstract-title">Abstract</div>
            <p class="is-size-6">
              Traditional high-quality 3D scanning and reconstruction typically relies on human labor to plan the scanning procedure. With the rapid development of embodied systems such as drones and robots, there is a growing demand of performing accurate 3D scanning and reconstruction in an fully automated manner. We introduce Auto3R, a data-driven uncertainty quantification model that is designed to automate the 3D scanning and reconstruction of scenes and objects, including objects with non-lambertian and specular materials. Specifically, in a process of iterative 3D reconstruction and scanning, Auto3R can make efficient and accurate prediction of uncertainty distribution over potential scanning viewpoints, without knowing the ground truth geometry and appearance. Through extensive experiments, Auto3R achieves superior performance that outperforms the state-of-the-art methods by a large margin. We also deploy Auto3R on a robot arm equipped with a camera and demonstrate that Auto3R can be used to effectively digitize real-world 3D objects and delivers ready-to-use and photorealistic digital assets.
            </p>
          </div>
          
          <!-- Buttons -->
          <div class="button-container">
            <a href="https://github.com/tomatoma00/Auto3R" target="_blank" class="button is-primary is-medium">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>View on GitHub</span>
            </a>

            <a href="https://arxiv.org/" target="_blank" class="button is-info is-medium">
              <span class="icon">
                <i class="ai ai-arxiv"></i>
              </span>
              <span>ArXiv</span>
            </a>
          </div>
          
          <!-- Video -->
          <div class="media-container">
            <div class="media-title">Demo Video</div>
            <video controls class="mt-2" style="max-width: 100%; height: auto;">
              <source src="./static/images/video.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          
          <!-- Comparison Image -->
          <div class="media-container">
            <div class="media-title">Results Comparison</div>
            <img src="./static/images/5normalnew.png" alt="Comparison of Auto3R with other methods" class="mt-2" style="max-width: 100%; height: auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

</body>
</html>
